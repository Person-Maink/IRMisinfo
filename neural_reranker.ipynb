{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whoosh.fields import Schema, TEXT, ID\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"indexdir\"):\n",
    "    os.mkdir(\"indexdir\")\n",
    "\n",
    "schema = Schema(docid=TEXT(stored=True), title=ID(stored=True), content=TEXT(stored=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygaggle.rerank.base import Query, Text\n",
    "from pygaggle.rerank.transformer import MonoT5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Excel with BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def save_bm25_to_excel(bm25_results_file, output_excel_file=\"bm25_results.xlsx\"):\n",
    "    with open(bm25_results_file, 'r') as f:\n",
    "        bm25_results_data = json.load(f)\n",
    "\n",
    "    rows = []\n",
    "    \n",
    "    for topic in bm25_results_data:\n",
    "        topic_id = topic[0][\"topic_id\"]\n",
    "        description = topic[0][\"question\"]\n",
    "        \n",
    "        for rank, result in enumerate(topic):\n",
    "            doc_id = result[\"docid\"]\n",
    "            doc_content = result[\"content\"]\n",
    "            score = result[\"score\"]\n",
    "            rows.append([topic_id, description, doc_id, rank + 1, score,doc_content])\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=['q_id', 'q_data', 'doc_id', 'rank', 'score', 'doc_data'])\n",
    "    df.to_excel(output_excel_file, index=False)\n",
    "\n",
    "    print(f\"Results saved to {output_excel_file}\")\n",
    "\n",
    "bm25_results_file = 'json_results_newest.json'  #\n",
    "save_bm25_to_excel(bm25_results_file, output_excel_file=\"bm25_results.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoTokenizer,T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('castorini/duot5-base-med-msmarco')\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)  \n",
    "    text = text.replace(\"\\n\", \" \").replace(\"\\r\", \"\") \n",
    "    return text[:32767] \n",
    "\n",
    "def rerank_with_monoT5(query_description, bm25_results, top_k=200):\n",
    "    query = Query(query_description)\n",
    "    passages = [\n",
    "        [result[\"doc_id\"], result[\"content\"],result[\"score\"]] for result in bm25_results[:top_k]\n",
    "    ]\n",
    " \n",
    "    texts = []\n",
    "    for p in passages:\n",
    "        doc_id = p[0]\n",
    "        doc_content = p[1]\n",
    "        \n",
    "        inputs = tokenizer(doc_content, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    \n",
    "        tokens = inputs[\"input_ids\"].squeeze(0)\n",
    "        attention_mask = inputs[\"attention_mask\"].squeeze(0)\n",
    "        token_type = inputs.get(\"token_type_ids\", None)  \n",
    "\n",
    "        texts.append(Text(doc_content, {'docid': doc_id, 'content': doc_content, 'tokens': tokens, 'attention_mask': attention_mask, 'token_type': token_type}, 0))\n",
    "\n",
    "    model = T5ForConditionalGeneration.from_pretrained('castorini/duot5-base-med-msmarco')\n",
    "    reranker = MonoT5(model=model)\n",
    "    reranked = reranker.rerank(query, texts)\n",
    "    reranked_results = sorted(reranked, key=lambda x: x.score, reverse=True)\n",
    "    \n",
    "    return reranked_results[:top_k]\n",
    "\n",
    "def save_to_excel(reranked_results, queries, file_path):\n",
    "    rows = []\n",
    "    for query, reranked in zip(queries, reranked_results):\n",
    "        query_id = query['topic_id']\n",
    "        query_description = query['description']\n",
    "        \n",
    "        for rank, result in enumerate(reranked):\n",
    "            doc_id = result[\"doc_id\"]\n",
    "            doc_content = clean_text(result[\"content\"])  \n",
    "            score = result[\"score\"]\n",
    "            rank = result[\"rank\"]\n",
    "            tokens = result[\"tokens\"]  \n",
    "            attention_mask = result[\"attention_mask\"]\n",
    "            token_type = result[\"token_type\"]\n",
    "           \n",
    "            rows.append([query_id, query_description, doc_id, rank + 1, score, tokens, attention_mask, token_type, doc_content])\n",
    "    \n",
    "    df = pd.DataFrame(rows, columns=['q_id', 'q_data', 'doc_id', 'rank', 'score', 'tokens', 'attention_mask', 'token_type', 'doc_data'])\n",
    "    df.to_excel(file_path, index=False)\n",
    "\n",
    "def eval_all_queries_and_save(bm25_results_file, top_k=200, output_excel_file=\"reranked_results.xlsx\"):\n",
    " \n",
    "    with open(bm25_results_file, 'r') as f:\n",
    "        bm25_results_data = json.load(f)\n",
    "\n",
    "    results_all = []\n",
    "    queries = []\n",
    "\n",
    "    i = 0\n",
    "    for topic in bm25_results_data:\n",
    "        print(i)\n",
    "        i+=1\n",
    "        if (i<=100):\n",
    "            topic_results = []\n",
    "            topic_id = topic[0][\"topic_id\"]\n",
    "            description = topic[0][\"question\"]\n",
    "            queries.append({\"topic_id\": topic_id, \"description\": description})\n",
    "        \n",
    "            bm25_results = [\n",
    "                {\"topic_id\": topic_id, \"doc_id\": result[\"docid\"], \"rank\": result[\"rank\"], \"score\": result[\"score\"], \"content\": result[\"content\"]}\n",
    "                for result in topic\n",
    "            ]\n",
    "            \n",
    "            reranked_results = rerank_with_monoT5(description, bm25_results)\n",
    "    \n",
    "            for rank, reranked in enumerate(reranked_results):\n",
    "                    trec_entry = {\n",
    "                        \"topic_id\": topic_id,\n",
    "                        \"doc_id\": reranked.metadata[\"docid\"],\n",
    "                        \"content\": reranked.metadata[\"content\"],\n",
    "                        \"rank\": rank + 1,\n",
    "                        \"score\": reranked.score,\n",
    "                        \"tokens\" : reranked.metadata[\"tokens\"],\n",
    "                        \"attention_mask\" : reranked.metadata[\"attention_mask\"],\n",
    "                        \"token_type\" : reranked.metadata[\"token_type\"]\n",
    "                    }\n",
    "                    topic_results.append(trec_entry)\n",
    "                \n",
    "            results_all.append(topic_results)\n",
    "\n",
    "\n",
    "    save_to_excel(results_all, queries, output_excel_file)\n",
    "\n",
    "    print(f\"Results saved to {output_excel_file}\")\n",
    "    \n",
    " \n",
    "\n",
    "\n",
    "bm25_results_file = 'json_results_newest.json' \n",
    "eval_all_queries_and_save(bm25_results_file, output_excel_file=\"neural_rerank_results.xlsx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
